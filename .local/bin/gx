#!/usr/bin/env bash

set -eu

# Cache directory and expiry time
CACHE_DIR="${HOME}/.cache/gx"
CACHE_EXPIRY="5 minutes"
KUBECTL_TIMEOUT="5s"

# Colors
ORANGE='\033[0;33m'
NO_COLOR='\033[0m'

# Print usage
print_usage() {
  bin_name="$(basename "$0")"
  echo "Usage:
  $bin_name [ login ] <installation> [ <separator> <cluster> ]         Create kubeconfig for the given installation or cluster
  $bin_name ssh       <installation> [ <separator> <cluster> ] <node>  SSH into the given node
  $bin_name open      <installation>                           <app>   Get the URL for the given app
  $bin_name cluster   [ options ] <action> [ args ... ]                Manage clusters, actions: create, delete, list, status, keep

Arguments:
  <installation>  Name of the installation to create kubeconfig for, or SSH into.
  <separator>     Any non alphanumeric character surrounded by spaces or not. i.e. can be a single space.
  <cluster>       Name of the cluster to create kubeconfig for or SSH into (optional).
  <node>          Hostname or IP address of the node to SSH into.
  <app>           Name of the app to open.

Options:
  -h, --help      Show help message for any command and exit

Examples:
  $bin_name my-installation my-cluster
  $bin_name ssh my-installation my-cluster ip-11-1-111-11
  $bin_name open my-installation my-app
  $bin_name cluster create"
}

print_login_usage() {
  bin_name="$(basename "$0")"
  echo "Usage:
  $bin_name [ login ] <installation> [ <separator> <cluster> ]  Create kubeconfig for the given installation or cluster

Arguments:
  <installation>  Name of the installation to create kubeconfig for.
  <separator>     Any non-alphanumeric character surrounded by spaces or not. i.e. can be a single space.
  <cluster>       Name of the cluster to create kubeconfig for (optional).

Options:
  -h, --help      Show this help message and exit

Examples:
  $bin_name my-installation
  $bin_name my-installation my-cluster
  $bin_name login my-installation
  $bin_name login my-installation my-cluster
  $bin_name login my-installation-my-cluster
  $bin_name login my-installation / my-cluster"
}

print_open_usage() {
  bin_name="$(basename "$0")"
  echo "Usage:
  $bin_name open <installation> <app>  Get the URL for the given app

Arguments:
  <installation>  Name of the installation to open the app in.
  <app>           Name of the app to open.

Options:
  -h, --help      Show this help message and exit

Examples:
  $bin_name open my-installation my-app"
}

print_ssh_usage() {
  bin_name="$(basename "$0")"
  echo "Usage:
  $bin_name ssh <installation> [ <separator> <cluster> ] <node>  SSH into the given node

Arguments:
  <installation>  Name of the installation to SSH into.
  <separator>     Any non-alphanumeric character surrounded by spaces or not. i.e. can be a single space.
  <cluster>       Name of the cluster to SSH into (optional).
  <node>          Hostname or IP address of the node to SSH into.

Options:
  -h, --help      Show this help message and exit

Examples:
  $bin_name ssh my-installation ip-11-1-111-11
  $bin_name ssh my-installation my-cluster ip-11-1-111-11
  $bin_name ssh my-installation / my-cluster ip-11-1-111-11
  $bin_name ssh my-installation-my-cluster ip-11-1-111-11"
}

print_cluster_usage() {
  bin_name="$(basename "$0")"
  echo "Usage:
  $bin_name cluster create  [ cluster_name ] [ options ]  Create a new cluster
  $bin_name cluster delete  [ cluster_name ] [ options ]  Delete an existing cluster
  $bin_name cluster list                                  List all clusters
  $bin_name cluster status  [ cluster_name ]              Show the status of a cluster
  $bin_name cluster keep    [ cluster_name ] [ options ]  Keep a cluster until a specified date

Arguments:
  <cluster_name>  Name of the cluster to manage. If not provided, defaults to the current user name.

Options:
      --interactive  Use interactive mode to select installation, release, and other options.
      --nodes-max    Maximum number of nodes in the cluster (default: 10)
      --nodes-min    Minimum number of nodes in the cluster (default: 3)
  -u, --until        Date until the cluster should be kept (default: tomorrow)

Examples:
  gx cluster create --interactive
  gx cluster delete my-cluster
  gx cluster list
  gx cluster status my-cluster
  gx cluster keep my-cluster --until '2023-12-31'
  gx cluster create --nodes-max 5 --nodes-min 2 --until '2023-12-31'"
}

validate_args() {
  local num_args="$1"; shift
  local usage_function="$1"; shift

  if "$show_help"; then
    $usage_function
    exit 0
  fi

  if [[ $# -lt "$num_args" ]]; then
    echo_stderr "ERROR: Missing arguments"
    $usage_function
    exit 1
  fi

  return 0
}

echo_stderr() {
    >&2 echo "$@"
}

log() {
  echo -e "â–º $*" 1>&2
}

# Join arguments with a separator
join_by() {
  local IFS="$1"
  shift
  echo "$*"
}

# Download and cache tsh data
# It accepts any tsh command and caches the result in a file
# The cache file is named after the command
tsh_cache() {
  local tsh_cmd="$*"
  cache_name="$(join_by "_" "$tsh_cmd")"
  local cache_file="$CACHE_DIR/tsh_${cache_name}.json"

  mkdir -p "${CACHE_DIR}"
  expiry="$(date -d "- $CACHE_EXPIRY" +%s)"
  if [[ ! -f "$cache_file" ]] || [[ "$(stat --printf=%Y "$cache_file")" -le "$expiry" ]]; then
    log "Downloading tsh $tsh_cmd"
    tsh $tsh_cmd --format json > "$cache_file"
  fi

  cat "$cache_file"
}

# Replace non-alphanumeric characters with spaces
get_clusters_names() {
  if [[ "$*" =~ leopard ]]; then
    log "${ORANGE}Warning${NO_COLOR} vpn access doesn't work for leopard, see: https://github.com/giantswarm/installations/tree/master/leopard#access-resources-via-teleport"
  fi

  # replace separator with space
  echo -n "$@" | sed -e 's/[^[:alnum:]]\+/ /1'
}

create_kubeconfig() {
  validate_args 1 print_login_usage "$@"

  # split words on spaces
  read -r -a values <<< "$(get_clusters_names "$@")"

  # installation is always the first value
  local installation="${values[0]}"
  local cluster=""

  # context_match is used to filter kubectl contexts by regex
  local context_matcher="${installation}$"
  # tsh_matcher is used to filter tsh clusters by name
  local tsh_matcher="${installation}"

  # if there are more than 2 values, the last one is the cluster
  if [[ ${#values[@]} -ge 2 ]]; then
    cluster="${values[1]}"
    context_matcher="${installation}-${cluster}"
    tsh_matcher="${installation}-${cluster}"
  fi

  # Check if the kubectl context already exists
  if CONTEXTS=$(kubectl config get-contexts -oname | grep "${context_matcher}"); then
    log "Checking for existing kubectl contexts"
    for c in $CONTEXTS; do
      # Test if the context is valid and switch to it if it is
      timeout "$KUBECTL_TIMEOUT" kubectl --context "${c}" get nodes &>/dev/null && \
        kubectl config use-context "${c}" && \
        exit 0
      done
  fi

  # Check if the cluster exists in tsh
  tsh_ok="$(tsh_cache kube ls | jq '.[] | select(.kube_cluster_name == "'"$tsh_matcher"'") | true')"

  # use tsh or opsctl to login
  local cmd=""
  if [[ "$tsh_ok" == "true" ]]; then
    cmd="tsh kube login ${tsh_matcher}"
  else
    cmd="opsctl login ${installation} ${cluster}"
  fi

  (
    set -ex
    $cmd
  )
}

open_app() {
  validate_args 2 print_open_usage "$@"

  installation="$(get_clusters_names "$1")"
  local app_name="$2"

  tsh_app_name="$(tsh_cache apps ls | jq -r '.[] | select((.metadata.labels["cluster"] == "'"$installation"'") and (.metadata.labels["app"] == "'"$app_name"'")) | .metadata.name')"
  local cmd=""
  if [[ -n "$tsh_app_name" ]]; then
    cmd="tsh app login ${tsh_app_name}"
  else
    cmd="opsctl open --app ${app_name} --installation ${installation} --no-browser"
  fi

  (
    set -ex
    $cmd | tail -n 1 | xargs
  )
}

ssh_node() {
  validate_args 2 print_ssh_usage "$@"

  # node is always the last argument
  local node="${*: -1}"

  # remove the last argument from the list
  set -- "${@:1:$#-1}"
  # split words on spaces
  read -r -a values <<< "$(get_clusters_names "$@")"

  # installation is always the first value
  local installation="${values[0]}"
  local cluster_name=""

  if [[ ${#values[@]} -ge 2 ]]; then
    cluster_name="${values[1]}"
  fi

  # Check if the node exists in tsh
  node_matcher="$(echo "${node}" | cut -d'.' -f1)"
  tsh_ok="$(tsh_cache ls | jq '.[] | select((.spec.hostname == "'"$node_matcher"'") and (.metadata.labels["ins"] == "'"$installation"'") and (.metadata.labels["cluster"] == "'"${cluster_name:-$installation}"'")) | true')"

  # use tsh or opsctl to ssh
  local cmd=""
  if [[ "$tsh_ok" == "true" ]]; then
    cmd="tsh ssh root@ins=${installation},cluster=${cluster_name:-$installation},node=${node_matcher}"
  else
    cmd="opsctl ssh ${installation} ${node}"
  fi

  (
    set -ex
    $cmd
  )
}

get_installation() {
	interactive=${1:-false}

  echo_stderr -n "> installation: "
	if $interactive; then
		name=$(opsctl list installations -s | tr ' ' '\n'|fzf --tac)
		create_kubeconfig "$name" &>/dev/null
	fi

	installation="$(kubectl config current-context | cut -d- -f2-)"
  if [[ -z "$installation" ]]; then
    echo_stderr "not found!"
    echo_stderr "> stopping"
    return 1
  fi
  if echo "$installation" | grep -q '-'; then
    echo_stderr "$installation - invalid!"
    echo_stderr "> stopping"
    return 1
  fi
  echo_stderr "$installation"

	echo "$installation"
}

get_release() {
  local provider="$1"
	local interactive=${2:-false}

  local release=""

  echo_stderr -n "> release: "
  if [[ ! "$provider" =~ ^cap.+ ]]; then
    release="$(get_release_vintage $interactive)"
  else
    release="$(get_release_capi $interactive)"
  fi

  if [[ -z "$release" ]]; then
    echo_stderr "not found!"
    echo_stderr "> stopping"
    return 1
  fi
  echo_stderr "$release"

  echo "$release"
}

get_release_vintage() {
	interactive=${1:-false}

	releases=$(kubectl get release -ojson)
	len=$(echo "$releases" | jq -r '.items | length')
	release_candidates=()
	for (( i=$len-1; i>=0; i-- )); do
		name=$(echo "$releases" | jq -r ".items[$i].metadata.name")
		state=$(echo "$releases" | jq -r ".items[$i].spec.state")
		ready=$(echo "$releases" | jq -r ".items[$i].status.ready")
		#echo -e "> name  : $name\n  active: $state\n  ready : $ready"
		if echo "$name" | grep -vq "-" && [[ "$ready" == "true" ]]; then
			if $interactive; then
				release_candidates+=("$name")
			else
				echo "$name"
				return
			fi
		fi
	done

	if $interactive && [[ ${#release_candidates[@]} -gt 0 ]]; then
		name=$(printf '%s\n' "${release_candidates[@]}" | fzf)
		echo "$name"
	fi
}

get_release_capi() {
	interactive=${1:-false}

	releases=$(kubectl get release -ojson)
	len=$(echo "$releases" | jq -r '.items | length')
	release_candidates=()
	for (( i=$len-1; i>=0; i-- )); do
		name=$(echo "$releases" | jq -r ".items[$i].metadata.name")
		state=$(echo "$releases" | jq -r ".items[$i].spec.state")
		ready=$(echo "$releases" | jq -r ".items[$i].status.ready")
		#echo -e "> name  : $name\n  active: $state\n  ready : $ready"
    if [ $(echo "$name" | grep -o - | wc -l) -lt 2 ] && [[ "$state" == "active" ]]; then
      release_name="$(echo "$name" | cut -d- -f2)"
			if $interactive; then
				release_candidates+=("$release_name")
			else
				echo "$release_name"
				return
			fi
		fi
	done

	if $interactive && [[ ${#release_candidates[@]} -gt 0 ]]; then
		name=$(printf '%s\n' "${release_candidates[@]}" | fzf)
		echo "$name"
	fi
}

cluster() {
  validate_args 1 print_cluster_usage "$@"

  local action="$1"; shift
  local cluster_name="${1:-$USER}"
  local organization="${USER}"

  cluster_namespace="$(kubectl get cl -Algiantswarm.io/cluster="$cluster_name" -ojson|jq -r '.items[0].metadata.namespace')"

  case "$action" in
    "list")
      kubectl gs get clusters -A
      exit;;
    "status")
      clusterctl describe cluster "$cluster_name" --namespace="$cluster_namespace" --show-conditions=all
      exit;;
    "keep")
      kubectl label cluster "$cluster_name" --namespace="$cluster_namespace" --overwrite=true  keep-until="$until"
      exit;;
  esac

  installation="$(get_installation $interactive)"

  echo_stderr -n "> provider: "
  provider="$(opsctl show installation -i "$installation" -ojson | jq -r .Provider)"
  echo_stderr "$provider"

  release="$(get_release "$provider" $interactive)"
  release_arg="--release $release"

  echo_stderr -n "> availability zone: "
  zone="$(kubectl get node -ojson | jq -r '.items[0].metadata.labels["topology.kubernetes.io/zone"]')"
  if [[ -z "$zone" ]] || [[ "$zone" == "null" ]]; then
    echo_stderr "not found!"
    echo_stderr "> stopping"
    exit 1
  fi
  echo_stderr "$zone"

  case "$action" in
    "create")
      set -ex
      kubectl gs template organization \
        --name "$organization" \
        | kubectl apply -f - || echo 1

      kubectl gs template cluster \
        --provider "$provider" \
        $release_arg \
        --name "$cluster_name" \
        --label "keep-until=$until" \
        --organization "$organization" \
        --description "$cluster_name test cluster" \
        | kubectl apply -f -

      if [[ ! "$provider" =~ ^cap.+ ]]; then
        kubectl-gs template nodepool --provider "$provider" \
          $release_arg \
          --cluster-name "$cluster_name" \
          --availability-zones "$zone" \
          --organization "$organization" \
          --description "$cluster_name nodepool" \
          --nodes-max "$nodes_max" \
          --nodes-min "$nodes_min" \
          | kubectl apply -f -
      fi
      ;;
    "delete")
      set -ex
      if [[ ! "$provider" =~ ^cap.+ ]]; then
        kubectl-gs template nodepool --provider "$provider" \
          --release "$release" \
          --cluster-name "$cluster_name" \
          --availability-zones "$zone" \
          --organization "$organization" \
          --description "$cluster_name nodepool" \
          --nodes-max "$nodes_max" \
          | kubectl delete --wait=false --ignore-not-found=true -f - || echo 1
      fi

      kubectl gs template cluster \
        --provider "$provider" \
        --release "$release" \
        --name "$cluster_name" \
        --organization "$organization" \
        --description "$cluster_name test cluster" \
        | kubectl delete --wait=false --ignore-not-found=true -f - || echo 1
      ;;
    *)
      echo "invalid action: $action"
      exit 1;;
  esac

  set +x

  echo "> success"
}

main() {
  interactive=false
  nodes_max=10
  nodes_min=3
  until=$(date -d tomorrow --utc +"%Y-%m-%d")
  show_help=false

  # Process arguments
  args=()
  while [[ $# -gt 0 ]]; do
    case $1 in
      -h|--help)
        # Display help message and exit.
        show_help=true;;
      --interactive)
        interactive=true;;
      --nodes-max)
        [[ -z "${2-}" ]] && echo "ERROR: $1 requires an argument." >&2 && exit 1
        nodes_max="$2"; shift;;
      --nodes-min)
        [[ -z "${2-}" ]] && echo "ERROR: $1 requires an argument." >&2 && exit 1
        nodes_min="$2"; shift;;
      -u|--until)
        [[ -z "${2-}" ]] && echo "ERROR: $1 requires an argument." >&2 && exit 1
        until=$(date -d "$2" --utc +"%Y-%m-%d"); shift;;
      -?*)
        echo "WARN: Unknown option $1" >&2;;
      *)
        args+=("$1");;
    esac
    shift
  done

  set -- "${args[@]}"

  # Require at least one argument
  if [[ $# -lt 1 ]]; then
    print_usage
    exit 0
  fi

  case "$1" in
    open)
      shift
      open_app "$@";;
    ssh)
      shift
      ssh_node "$@";;
    cluster)
      shift
      cluster "$@";;
    login)
      shift;& # fallthrough
    *)
      create_kubeconfig "$@";;
  esac
}

main "$@"
